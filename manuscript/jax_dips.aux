\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{pakravan2021solving}
\Newlabel{cor}{1}
\Newlabel{1}{a}
\Newlabel{2}{b}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec::introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{MIN2007300}
\citation{MIN2007300}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Life sciences are described by elliptic PDEs with free interfaces}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Level-set method for free boundary problems}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Interpolation methods}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Trilinear interpolation}{2}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Quadratic non-oscillatory interpolation}{2}{subsubsection.2.1.2}\protected@file@percent }
\citation{osher1988fronts}
\citation{SUSSMAN1994146}
\citation{XIU2001658}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Level-set method}{3}{subsection.2.2}\protected@file@percent }
\newlabel{eq::sussman}{{2}{3}{Level-set method}{equation.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Second order accurate semi-Lagrangian advection scheme}{3}{subsubsection.2.2.1}\protected@file@percent }
\citation{shu1988efficient}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Godunov Hamiltonian for reinitialization}{4}{subsubsection.2.2.2}\protected@file@percent }
\citation{shu1988efficient}
\citation{min2007geometric}
\citation{sallee1984middle}
\citation{min2007geometric}
\citation{min2007geometric}
\citation{min2007geometric}
\citation{min2007geometric}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Geometric operations}{5}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Integration over 3D surfaces and volumes}{5}{subsubsection.2.3.1}\protected@file@percent }
\citation{min2007geometric}
\citation{min2007geometric}
\citation{min2007geometric}
\citation{min2007geometric}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Cross sections of interface with grid cell faces}{6}{subsubsection.2.3.2}\protected@file@percent }
\citation{hecht1987kolmogorov}
\citation{kolmogorov1957representation}
\citation{sprecher1965structure}
\citation{ismailov2022}
\@writefile{toc}{\contentsline {section}{\numberline {3}Hybrid Interfacial PDE Solver Strategy}{7}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Preconditioners are ideal network regularizers}{7}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Neural network approximators for the solution}{7}{subsection.3.2}\protected@file@percent }
\citation{kingma2014adam}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Workflow I: full preservation of the numerical solver to the train neural network surrogate model. Training occurs in the finite dimensional space spanned by the finite discretization methods.\relax }}{8}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:proposal}{{1}{8}{Workflow I: full preservation of the numerical solver to the train neural network surrogate model. Training occurs in the finite dimensional space spanned by the finite discretization methods.\relax }{figure.caption.1}{}}
\citation{optax2020github}
\citation{kingma2014adam}
\citation{gradClipping}
\citation{bochkov2020solving}
\citation{bochkov2020solving}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Workflow II: stronger merger of the numerical solver with the neural network surrogate model. Training occurs in the finite dimensional space spanned by the finite discretization method.\relax }}{9}{figure.caption.2}\protected@file@percent }
\newlabel{fig:proposal}{{2}{9}{Workflow II: stronger merger of the numerical solver with the neural network surrogate model. Training occurs in the finite dimensional space spanned by the finite discretization method.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Approach I. Finite discretization method fused with regression extrapolation}{9}{subsection.3.3}\protected@file@percent }
\newlabel{sec::FD}{{3.3}{9}{Approach I. Finite discretization method fused with regression extrapolation}{subsection.3.3}{}}
\citation{bochkov2020solving}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Two neural networks are defined for the two regions of the computational domain.\relax }}{10}{figure.caption.3}\protected@file@percent }
\newlabel{fig:shapes}{{3}{10}{Two neural networks are defined for the two regions of the computational domain.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Notation used in this paper. Close to the interface where finite volumes are crossed by the interface, there are extra degrees of freedom (open circles) that are extrapolations of solutions from each domain to the opposite domain. Jump conditions are implicitly encoded in these extrapolated values.\relax }}{11}{figure.caption.4}\protected@file@percent }
\newlabel{fig:grid}{{4}{11}{Notation used in this paper. Close to the interface where finite volumes are crossed by the interface, there are extra degrees of freedom (open circles) that are extrapolations of solutions from each domain to the opposite domain. Jump conditions are implicitly encoded in these extrapolated values.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Approach II. Finite discretization method fused with neural extrapolation}{13}{subsection.3.4}\protected@file@percent }
\newlabel{eq::taylorexpandjump}{{13}{13}{Approach II. Finite discretization method fused with neural extrapolation}{equation.3.13}{}}
\newlabel{eq::extrapolate1}{{14}{13}{Approach II. Finite discretization method fused with neural extrapolation}{equation.3.14}{}}
\newlabel{eq::extrapolate2}{{15}{13}{Approach II. Finite discretization method fused with neural extrapolation}{equation.3.15}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Bias Slow approximation of the non-existing solution value on a grid point based on existing solution values in its neighborhood. The notation is used for $u_{i,j}^\pm =B_{i,j}^\pm : \mathbf  {U}_{i,j}+r_{i,j}^\pm $.\relax }}{14}{algorithm.1}\protected@file@percent }
\newlabel{euclid}{{1}{14}{Bias Slow approximation of the non-existing solution value on a grid point based on existing solution values in its neighborhood. The notation is used for $u_{i,j}^\pm =B_{i,j}^\pm : \mathbf {U}_{i,j}+r_{i,j}^\pm $.\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Approach III. Penalty minimization method}{15}{subsection.3.5}\protected@file@percent }
\newlabel{eq::interfaceLoss}{{17}{15}{Approach III. Penalty minimization method}{equation.3.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Numerical Examples}{15}{section.4}\protected@file@percent }
\citation{guittet2015solving}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Case I.}{16}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Convergence on the solution using the regression-based solver. We report $L^\infty $-norm error as well as root-mean-squared-error (RMSE) of the solution field evaluated everywhere in the domain. Rightmost column reports the overall time to solution for \texttt  {JAX-DIPS} which constitutes $10,000$ epochs in each case and the initial compilation time of jaxpressions. The neural network has $982$ trainable parameters. In each case GPU compute occupancy is at $100\%$ on a single NVIDIA RTX A6000 GPU.\relax }}{16}{table.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Case II.}{16}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Loss evolution with epochs for the sphere (left) and star (right) examples.\relax }}{17}{figure.caption.6}\protected@file@percent }
\newlabel{fig:losses}{{5}{17}{Loss evolution with epochs for the sphere (left) and star (right) examples.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Illustration of three dimensional interface used (left), and $\mu ^\pm $ on the $16\times 16\times 16$ grid (right).\relax }}{17}{figure.caption.7}\protected@file@percent }
\newlabel{fig:sphere}{{6}{17}{Illustration of three dimensional interface used (left), and $\mu ^\pm $ on the $16\times 16\times 16$ grid (right).\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Illustration of numerical solution and absolute error using the regression based solver on a cross section of the domain. \relax }}{18}{figure.caption.8}\protected@file@percent }
\newlabel{fig:sphere}{{7}{18}{Illustration of numerical solution and absolute error using the regression based solver on a cross section of the domain. \relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Streamlines of solution gradient for (left) the surrogate neural model colored by model solution value, (right) exact streamlines colored by exact solution values. \relax }}{19}{figure.caption.9}\protected@file@percent }
\newlabel{fig:spheregrad}{{8}{19}{Streamlines of solution gradient for (left) the surrogate neural model colored by model solution value, (right) exact streamlines colored by exact solution values. \relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion \& Future Directions}{19}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Illustration of three dimensional interface used (left), and $\mu ^\pm $ on the $32\times 32\times 32$ grid (right).\relax }}{20}{figure.caption.10}\protected@file@percent }
\newlabel{fig:star}{{9}{20}{Illustration of three dimensional interface used (left), and $\mu ^\pm $ on the $32\times 32\times 32$ grid (right).\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Illustration of exact and numerical solutions.\relax }}{21}{figure.caption.11}\protected@file@percent }
\newlabel{fig:star_sol}{{10}{21}{Illustration of exact and numerical solutions.\relax }{figure.caption.11}{}}
\bibstyle{abbrv}
\bibdata{references}
\bibcite{bochkov2020solving}{{1}{}{{}}{{}}}
\bibcite{guittet2015solving}{{2}{}{{}}{{}}}
\bibcite{hecht1987kolmogorov}{{3}{}{{}}{{}}}
\bibcite{optax2020github}{{4}{}{{}}{{}}}
\bibcite{ismailov2022}{{5}{}{{}}{{}}}
\bibcite{kingma2014adam}{{6}{}{{}}{{}}}
\bibcite{kolmogorov1957representation}{{7}{}{{}}{{}}}
\bibcite{min2007geometric}{{8}{}{{}}{{}}}
\bibcite{MIN2007300}{{9}{}{{}}{{}}}
\bibcite{osher1988fronts}{{10}{}{{}}{{}}}
\bibcite{pakravan2021solving}{{11}{}{{}}{{}}}
\bibcite{gradClipping}{{12}{}{{}}{{}}}
\bibcite{sallee1984middle}{{13}{}{{}}{{}}}
\bibcite{shu1988efficient}{{14}{}{{}}{{}}}
\bibcite{sprecher1965structure}{{15}{}{{}}{{}}}
\bibcite{SUSSMAN1994146}{{16}{}{{}}{{}}}
\bibcite{XIU2001658}{{17}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {section}{References}{22}{section*.12}\protected@file@percent }
